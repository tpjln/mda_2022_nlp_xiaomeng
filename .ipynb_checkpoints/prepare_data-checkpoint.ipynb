{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072bdb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import requests\n",
    "import udf\n",
    "\n",
    "\n",
    "testmode=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c44f70",
   "metadata": {},
   "source": [
    "## Get speech text data from web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eee7a190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of speech url found:428\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#define URL for scraping\n",
    "theurl = \"https://www.americanrhetoric.com/barackobamaspeeches.htm\"\n",
    "thepage = urllib.request.urlopen(theurl)\n",
    "\n",
    "#Cooking the Soup\n",
    "soup = BeautifulSoup(thepage,\"html.parser\")\n",
    "\n",
    "web_list=[a_href[\"href\"] for a_href in soup.find_all(\"a\", href=True)]\n",
    "\n",
    "speech_web=[i for i in web_list if i.startswith(\"speeches\") and i.endswith('htm') ]\n",
    "\n",
    "start = speech_web.index('speeches/barackobama/barackobamainauguraladdress.htm')\n",
    "speech_president = speech_web[start:]\n",
    "\n",
    "# remove duplicate\n",
    "new = []\n",
    "[new.append(x) for x in speech_president if x not in new]\n",
    "\n",
    "speech_url = []\n",
    "for val in range(len(new)):\n",
    "    speech_url.append(\"https://www.americanrhetoric.com/\" + str(new[val])) \n",
    "\n",
    "# print(f'Total number of speech url found:{len(speech_url)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520ea050",
   "metadata": {},
   "source": [
    "## Get title and content of each speech text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12ebece1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(url):\n",
    "    headers = {\n",
    "            'User-Agent': \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.6; rv:2.0.1) Gecko/20100101 Firefox/4.0.1\"\n",
    "        }\n",
    "    resp = requests.get(url, headers=headers)\n",
    "    s = BeautifulSoup(resp.text, \"html.parser\")\n",
    "    title = s.title\n",
    "    text = s.get_text(strip=True)\n",
    "    return title, text\n",
    "\n",
    "\n",
    "if testmode is True:\n",
    "    speeches = [udf.scrab.extract_text(url) for url in speech_url[50:100]]\n",
    "else:\n",
    "    speeches = [udf.scrab.extract_text(url) for url in speech_url]\n",
    "    \n",
    "speech_content = [speeches[i][1] for i in range(len(speeches))]\n",
    "speech_title = [udf.scrab.title(speeches[i][0]) for i in range(len(speeches))]\n",
    "## remove cd, pdf ...\n",
    "speech_content = [udf.scrab.allowed(speech) for speech in speech_content]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99d8a67",
   "metadata": {},
   "source": [
    "## Take speeches in 2009.01.20 – 2017.01.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a38bbc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2009.01.20 – 2017.01.20 Obama has 428 speeches\n"
     ]
    }
   ],
   "source": [
    "year = [\"2009\",\"2010\",\"2011\",\"2012\",\"2013\",\"2014\",\"2015\",\"2016\",\"2017\"]\n",
    "if testmode is True:\n",
    "    year=[\"2009\",\"2010\"]\n",
    "\n",
    "date_list = []\n",
    "for i in range(len(year)):\n",
    "    date_list.extend(soup.find_all(string=re.compile(year[i])))\n",
    "    \n",
    "toBeRemoved = ['Press Conference on 2010 Budget Sent to Congress','Announcement of 2012 Presidential Candidacy', 'Honoring Golden State Warriors 2015 NBA Champs','Press Conference Following 2016 NATO Summit']\n",
    "if testmode  is True:\n",
    "    toBeRemoved=[]\n",
    "\n",
    "for i in range(len(toBeRemoved)):\n",
    "    date_list.remove(toBeRemoved[i])\n",
    "\n",
    "date = [str(x) for x in date_list[date_list.index(\"20 Jan 2009\"):]]\n",
    "\n",
    "# print(f'2009.01.20 – 2017.01.20 Obama has {len(date)} speeches')\n",
    "if testmode  is True:\n",
    "    date=date[0:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41399ac4",
   "metadata": {},
   "source": [
    "## Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08c33e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20 Jan 2009</td>\n",
       "      <td>First Presidential Inaugural Addre</td>\n",
       "      <td>[Chief Justice John G. \\r\\n\\t\\tRoberts adminis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24 Jan 2009</td>\n",
       "      <td>&gt;American Rhetoric: Barack Obama: First Presid...</td>\n",
       "      <td>: First Presidential Weekly Address \\r\\n(01-24...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26 Jan 2009</td>\n",
       "      <td>Al-Arabiya Television Intervi</td>\n",
       "      <td>- Al-Arabiya Television InterviewBarackObamaAl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                              title  \\\n",
       "0  20 Jan 2009                 First Presidential Inaugural Addre   \n",
       "1  24 Jan 2009  >American Rhetoric: Barack Obama: First Presid...   \n",
       "2  26 Jan 2009                      Al-Arabiya Television Intervi   \n",
       "\n",
       "                                             content  \n",
       "0  [Chief Justice John G. \\r\\n\\t\\tRoberts adminis...  \n",
       "1  : First Presidential Weekly Address \\r\\n(01-24...  \n",
       "2  - Al-Arabiya Television InterviewBarackObamaAl...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speech = pd.DataFrame({'date': date,'title':speech_title,'content':speech_content})\n",
    "print(\"Data before cleaned:\")\n",
    "df_speech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "589a9957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after cleaned:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>content_clean</th>\n",
       "      <th>content_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20 Jan 2009</td>\n",
       "      <td>First Presidential Inaugural Addre</td>\n",
       "      <td>I stand here today humbled \\r\\n\\t\\tby the task...</td>\n",
       "      <td>stand today humble task u grateful trust besto...</td>\n",
       "      <td>stand today task u trust bestow sacrifice bear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24 Jan 2009</td>\n",
       "      <td>First Presidential Weekly Address</td>\n",
       "      <td>We begin this year and this \\r\\n\\t\\tAdministra...</td>\n",
       "      <td>begin year administration midst unprecedented ...</td>\n",
       "      <td>year administration midst crisis call action w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26 Jan 2009</td>\n",
       "      <td>Al-Arabiya Television Intervi</td>\n",
       "      <td>- Al-Arabiya Television InterviewBarackObamaAl...</td>\n",
       "      <td>television television interview hisham melhemd...</td>\n",
       "      <td>television television interview hisham house w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                               title  \\\n",
       "0  20 Jan 2009  First Presidential Inaugural Addre   \n",
       "1  24 Jan 2009   First Presidential Weekly Address   \n",
       "2  26 Jan 2009       Al-Arabiya Television Intervi   \n",
       "\n",
       "                                             content  \\\n",
       "0  I stand here today humbled \\r\\n\\t\\tby the task...   \n",
       "1  We begin this year and this \\r\\n\\t\\tAdministra...   \n",
       "2  - Al-Arabiya Television InterviewBarackObamaAl...   \n",
       "\n",
       "                                       content_clean  \\\n",
       "0  stand today humble task u grateful trust besto...   \n",
       "1  begin year administration midst unprecedented ...   \n",
       "2  television television interview hisham melhemd...   \n",
       "\n",
       "                                       content_nouns  \n",
       "0  stand today task u trust bestow sacrifice bear...  \n",
       "1  year administration midst crisis call action w...  \n",
       "2  television television interview hisham house w...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_speech.iloc[0,2] = df_speech.iloc[0,2][df_speech.iloc[0,2].find(\"My fellow citizens:\")\n",
    "                                          +len(\"My fellow citizens:\"):df_speech.iloc[0,2].find(\"(Drudge Report)\")]\n",
    "## Make some edition\n",
    "df_speech.iloc[1,2] = df_speech.iloc[1,2][df_speech.iloc[1,2].find(\"[as prepared for delivery]\") + \n",
    "                                               len(\"[as prepared for delivery]\"):]\n",
    "df_speech.iloc[1,1] = df_speech.iloc[1,1][df_speech.iloc[1,1].find(\">American Rhetoric: Barack Obama:\")\n",
    "                                         +len(\">American Rhetoric: Barack Obama:\"):df_speech.iloc[1,1].find(\n",
    "                                         \"(01-24-0\")].strip()\n",
    "\n",
    "#Remove stopwords\n",
    "\n",
    "from nltk import WordNetLemmatizer\n",
    "StopWords = stopwords.words(\"english\")\n",
    "StopWords.extend([\"u\",\"from\"])\n",
    "\n",
    "def clean_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "        # Remove the punctuations\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "        # Lower the tokens\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "        # Remove stopword\n",
    "    tokens = [word for word in tokens if not word in StopWords]\n",
    "        # Lemmatize\n",
    "    lemma = WordNetLemmatizer()\n",
    "    tokens = [lemma.lemmatize(word, pos=\"v\") for word in tokens]\n",
    "    tokens = [lemma.lemmatize(word, pos=\"n\") for word in tokens]\n",
    "     # list to string\n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "    \n",
    "    \n",
    "df_speech[\"content_clean\"] = [clean_text(i) for i in df_speech[\"content\"].values.tolist() ]\n",
    "\n",
    "\n",
    "# Extract nouns from speeches\n",
    "def nouns_extract(cont):\n",
    "    nouns = []\n",
    "    cont = udf.transform.StringToList(cont)\n",
    "    for word, pos in nltk.pos_tag(cont):\n",
    "        if (pos == 'NN' or pos == 'NNP' or pos == 'NNS' or pos == 'NNPS'):\n",
    "            nouns.append(word)\n",
    "            string_nouns = udf.transform.ListToString(nouns)\n",
    "    return string_nouns\n",
    "    \n",
    "    \n",
    "# Extract nouns from speeches\n",
    "df_speech[\"content_nouns\"] = [nouns_extract(x) for x in df_speech[\"content_clean\"]]\n",
    "\n",
    "# df_speech=df_speech.drop(['content'], axis=1)\n",
    "\n",
    "print(\"Data after cleaned:\")\n",
    "df_speech.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7daee008",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to csv file: dfspeech_cleaned_all.csv\n"
     ]
    }
   ],
   "source": [
    "#Save data to file\n",
    "df_speech.to_csv('df_obama_speech.csv')\n",
    "print(\"Data saved to csv file: df_obama_speech.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
